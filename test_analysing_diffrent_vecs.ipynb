{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer where it works well : without instruct vector layer 24, multiplier 11 or 26, 15 or 16,9\n",
    "#layers where it works badly: without instruct vector layer22, 17, 23\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "from typing import List, Optional\n",
    "\n",
    "import fire\n",
    "\n",
    "from llama import Dialog, Llama\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "from data_casual import output_list_train, input_list_train, input_list_test, output_list_test\n",
    "from eval import extracting_steering_vector, calc_loss_steering_vector\n",
    "\n",
    "ckpt_dir = \"./\"\n",
    "tokenizer_path = \"./tokenizer.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ribbee02/VSC/llama3/llama/generation.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
      "/home/ribbee02/VSC/Coding_venv/lib/python3.11/site-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 11.44 seconds\n"
     ]
    }
   ],
   "source": [
    "generator = Llama.build(\"./\", \"./tokenizer.model\",max_seq_len= 2500,max_batch_size= 4, activation=True, activation_layer=24, steering_vector=torch.tensor(4096*[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to see which of our proposed vectors work the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He did not classify 0 questions with appropriate answers\n",
      "initial loss is 0.6927710843373532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35629/2453397639.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  steering_vec = torch.load(f\"./steering_vectors/n_vector{k}.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 1 is 0.6953528399311572\n",
      "He did not classify 9 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 3 is 0.5283993115318374\n",
      "He did not classify 3014 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 5 is 0.9535283993115485\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 1 is 0.5516351118760726\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 3 is 0.38037865748708743\n",
      "He did not classify 1263 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 5 is 0.5137693631669485\n",
      "He did not classify 3463 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 7 is 0.9698795180723067\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 1 is 0.5275387263339028\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 3 is 0.38984509466436784\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 5 is 0.2994836488812367\n",
      "He did not classify 2455 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 7 is 0.7306368330464773\n",
      "He did not classify 3324 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 9 is 0.9845094664371955\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 1 is 0.5335628227194452\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 3 is 0.519793459552491\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 5 is 0.30206540447504043\n",
      "He did not classify 614 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 7 is 0.3820998278829566\n",
      "He did not classify 2209 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 9 is 0.7547332185886472\n",
      "He did not classify 2671 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 11 is 0.9509466437177446\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 1 is 0.5920826161790006\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 3 is 0.5344234079173799\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 5 is 0.560240963855419\n",
      "He did not classify 563 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 7 is 0.7530120481927779\n",
      "He did not classify 1676 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 9 is 0.9337349397590519\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 17 loss with multiplier 1 is 0.6996557659208303\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 17 loss with multiplier 3 is 0.7392426850258237\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 17 loss with multiplier 5 is 0.7822719449225556\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 17 loss with multiplier 7 is 0.8227194492254836\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 1 is 0.6703958691910527\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 3 is 0.6652323580034448\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 5 is 0.6944922547332225\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 7 is 0.7108433734939806\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 9 is 0.7332185886402812\n",
      "He did not classify 182 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 11 is 0.7607573149741896\n",
      "He did not classify 1266 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 13 is 0.8640275387263462\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 1 is 0.6058519793459548\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 3 is 0.5869191049913928\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 5 is 0.5826161790017196\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 7 is 0.5344234079173799\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 9 is 0.5800344234079157\n",
      "He did not classify 98 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 11 is 0.5955249569707391\n",
      "He did not classify 1153 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 13 is 0.769363166953536\n",
      "He did not classify 2032 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 15 is 0.9294320137693787\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 1 is 0.6428571428571442\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 3 is 0.6342512908777979\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 5 is 0.6222030981067129\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 7 is 0.6428571428571442\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 9 is 0.6376936316695364\n",
      "He did not classify 2 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 11 is 0.6419965576592096\n",
      "He did not classify 275 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 13 is 0.6721170395869219\n",
      "He did not classify 1174 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 15 is 0.819277108433745\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 1 is 0.6333907056798632\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 3 is 0.5714285714285693\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 5 is 0.5215146299483603\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 7 is 0.5060240963855368\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 9 is 0.49139414802064857\n",
      "He did not classify 1 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 11 is 0.49225473321858315\n",
      "He did not classify 174 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 13 is 0.5335628227194452\n",
      "He did not classify 885 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 15 is 0.6574870912220331\n",
      "He did not classify 1700 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 17 is 0.8519793459552613\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 1 is 0.6824440619621376\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 3 is 0.700516351118765\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 5 is 0.6979345955249611\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 7 is 0.6876075731497454\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 9 is 0.7082616179001767\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 11 is 0.7177280550774577\n",
      "He did not classify 31 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 13 is 0.7134251290877845\n",
      "He did not classify 308 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 15 is 0.7616179001721243\n",
      "He did not classify 920 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 17 is 0.8537005163511305\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 1 is 0.6936316695352879\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 3 is 0.709982788296046\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 5 is 0.6893287435456147\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 7 is 0.6669535283993141\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 9 is 0.6738382099827912\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 11 is 0.6574870912220331\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 13 is 0.6523235800344253\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 15 is 0.68846815834768\n",
      "He did not classify 40 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 17 is 0.6798623063683337\n",
      "He did not classify 223 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 19 is 0.7323580034423466\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 1 is 0.6729776247848566\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 3 is 0.62908777969019\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 5 is 0.6153184165232358\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 7 is 0.5783132530120464\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 9 is 0.5516351118760726\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 11 is 0.5146299483648832\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 13 is 0.5240963855421642\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 15 is 0.5309810671256413\n",
      "He did not classify 2 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 17 is 0.5154905335628178\n",
      "He did not classify 104 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 19 is 0.5111876075731446\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 1 is 0.6893287435456147\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 3 is 0.6703958691910527\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 5 is 0.6557659208261638\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 7 is 0.6540447504302945\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 9 is 0.6394148020654057\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 11 is 0.6359724612736671\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 13 is 0.5998278829604123\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 15 is 0.5783132530120464\n",
      "He did not classify 20 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 17 is 0.591222030981066\n",
      "He did not classify 190 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 19 is 0.5808950086058503\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 1 is 0.6703958691910527\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 3 is 0.6824440619621376\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 5 is 0.6772805507745298\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 7 is 0.660068846815837\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 9 is 0.6488812392426867\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 11 is 0.6514629948364906\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 13 is 0.6187607573149744\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 15 is 0.5697074010327\n",
      "He did not classify 84 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 17 is 0.6110154905335626\n",
      "He did not classify 352 questions with appropriate answers\n",
      "Layer 26 loss with multiplier 19 is 0.6617900172117063\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 1 is 0.6626506024096409\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 3 is 0.638554216867471\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 5 is 0.6256454388984515\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 7 is 0.5972461273666084\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 9 is 0.5895008605851967\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 11 is 0.550774526678138\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 13 is 0.5318416523235759\n",
      "He did not classify 28 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 15 is 0.5232358003442296\n",
      "He did not classify 246 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 17 is 0.5516351118760726\n",
      "He did not classify 828 questions with appropriate answers\n",
      "Layer 27 loss with multiplier 19 is 0.6652323580034448\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 1 is 0.669535283993118\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 3 is 0.6359724612736671\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 5 is 0.6273666092943208\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 7 is 0.6213425129087783\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 9 is 0.5955249569707391\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 11 is 0.6032702237521509\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 13 is 0.6084337349397587\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 15 is 0.5826161790017196\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 17 is 0.5851979345955235\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 28 loss with multiplier 19 is 0.5688468158347654\n"
     ]
    }
   ],
   "source": [
    "initial_loss = calc_loss_steering_vector(generator, torch.tensor(4096*[0]), (input_list_test, output_list_test), layer=10, iter=len(input_list_test), multiplier=0)\n",
    "losses_normal_vectors = {}\n",
    "print(f\"initial loss is {initial_loss}\")\n",
    "for k in range(12,29):\n",
    "    steering_vec = torch.load(f\"./steering_vectors/n_vector{k}.pt\")\n",
    "    for multiplier in range(1,20,2):\n",
    "        loss = calc_loss_steering_vector(generator, steering_vec, (input_list_test, output_list_test), layer=k, iter=len(input_list_test), multiplier=multiplier)\n",
    "        print(f\"Layer {k} loss with multiplier {multiplier} is {loss}\")\n",
    "        losses_normal_vectors[f\"{k},{multiplier}\"] = loss\n",
    "        if loss>0.8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He did not classify 0 questions with appropriate answers\n",
      "initial loss is 0.6979345955249611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35629/2227771769.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  steering_vec = torch.load(f\"./steering_without_instruct/n_vector{k}.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 1 is 0.6721170395869219\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 3 is 0.49741824440619065\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 5 is 0.39414802065404075\n",
      "He did not classify 157 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 7 is 0.3416523235800312\n",
      "He did not classify 2849 questions with appropriate answers\n",
      "Layer 12 loss with multiplier 9 is 1.0000000000000189\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 1 is 0.6445783132530135\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 3 is 0.5327022375215106\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 5 is 0.5025817555937983\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 7 is 0.43803786574870446\n",
      "He did not classify 2697 questions with appropriate answers\n",
      "Layer 13 loss with multiplier 9 is 0.8012048192771176\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 1 is 0.6488812392426867\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 3 is 0.4939759036144523\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 5 is 0.5232358003442296\n",
      "He did not classify 23 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 7 is 0.5740103270223732\n",
      "He did not classify 575 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 9 is 0.5920826161790006\n",
      "He did not classify 1162 questions with appropriate answers\n",
      "Layer 14 loss with multiplier 11 is 1.0000000000000189\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 1 is 0.6179001721170397\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 3 is 0.5206540447504256\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 5 is 0.6230636833046476\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 7 is 0.638554216867471\n",
      "He did not classify 666 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 9 is 0.5972461273666084\n",
      "He did not classify 1165 questions with appropriate answers\n",
      "Layer 15 loss with multiplier 11 is 1.0000000000000189\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 1 is 0.6833046471600722\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 3 is 0.6265060240963861\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 5 is 0.6841652323580069\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 7 is 0.7461273666093008\n",
      "He did not classify 8 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 9 is 0.62908777969019\n",
      "He did not classify 1452 questions with appropriate answers\n",
      "Layer 16 loss with multiplier 11 is 0.9793459552495877\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 17 loss with multiplier 1 is 0.7134251290877845\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 17 loss with multiplier 3 is 0.7581755593803857\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 17 loss with multiplier 5 is 0.8012048192771176\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 1 is 0.7220309810671309\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 3 is 0.7418244406196276\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 5 is 0.7771084337349478\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 7 is 0.7530120481927779\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 9 is 0.6738382099827912\n",
      "He did not classify 438 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 11 is 0.5774526678141118\n",
      "He did not classify 2153 questions with appropriate answers\n",
      "Layer 18 loss with multiplier 13 is 0.9913941480206726\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 1 is 0.6462994836488828\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 3 is 0.6394148020654057\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 5 is 0.6850258175559415\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 7 is 0.6110154905335626\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 9 is 0.4165232358003399\n",
      "He did not classify 433 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 11 is 0.3519793459552462\n",
      "He did not classify 2080 questions with appropriate answers\n",
      "Layer 19 loss with multiplier 13 is 0.990533562822738\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 1 is 0.641135972461275\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 3 is 0.6376936316695364\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 5 is 0.6213425129087783\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 7 is 0.5180722891566217\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 9 is 0.3864027538726295\n",
      "He did not classify 14 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 11 is 0.25129087779690007\n",
      "He did not classify 949 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 13 is 0.6032702237521509\n",
      "He did not classify 1416 questions with appropriate answers\n",
      "Layer 20 loss with multiplier 15 is 0.9991394148020843\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 1 is 0.6445783132530135\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 3 is 0.6092943201376934\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 5 is 0.538726333907053\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 7 is 0.40963855421686324\n",
      "He did not classify 4 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 9 is 0.2986230636833021\n",
      "He did not classify 238 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 11 is 0.3631669535283958\n",
      "He did not classify 815 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 13 is 0.5800344234079157\n",
      "He did not classify 1879 questions with appropriate answers\n",
      "Layer 21 loss with multiplier 15 is 0.9148020654044898\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 1 is 0.68846815834768\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 3 is 0.7366609294320198\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 5 is 0.7667814113597321\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 7 is 0.759896729776255\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 9 is 0.7358003442340851\n",
      "He did not classify 3 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 11 is 0.6549053356282292\n",
      "He did not classify 753 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 13 is 0.6962134251290918\n",
      "He did not classify 2094 questions with appropriate answers\n",
      "Layer 22 loss with multiplier 15 is 0.931153184165248\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 1 is 0.7332185886402812\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 3 is 0.7564543889845164\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 5 is 0.7332185886402812\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 7 is 0.68846815834768\n",
      "He did not classify 1 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 9 is 0.5963855421686738\n",
      "He did not classify 122 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 11 is 0.4948364888123869\n",
      "He did not classify 753 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 13 is 0.6325301204819286\n",
      "He did not classify 1795 questions with appropriate answers\n",
      "Layer 23 loss with multiplier 15 is 0.8476764199655881\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 1 is 0.6893287435456147\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 3 is 0.6488812392426867\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 5 is 0.5946643717728045\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 7 is 0.5137693631669485\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 9 is 0.4216867469879474\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 11 is 0.32099827882960125\n",
      "He did not classify 152 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 13 is 0.28227194492254504\n",
      "He did not classify 990 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 15 is 0.5249569707400988\n",
      "He did not classify 2062 questions with appropriate answers\n",
      "Layer 24 loss with multiplier 17 is 0.9044750430292742\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 1 is 0.681583476764203\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 3 is 0.681583476764203\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 5 is 0.6230636833046476\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 7 is 0.5869191049913928\n",
      "He did not classify 0 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 9 is 0.500860585197929\n",
      "He did not classify 68 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 11 is 0.4406196213425082\n",
      "He did not classify 783 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 13 is 0.5180722891566217\n",
      "He did not classify 1808 questions with appropriate answers\n",
      "Layer 25 loss with multiplier 15 is 0.8141135972461372\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m steering_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./steering_without_instruct/n_vector\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m multiplier \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_loss_steering_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteering_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_list_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_list_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiplier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss with multiplier \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmultiplier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     losses_wo_instruct_vectors[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmultiplier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/VSC/llama3/eval/eval.py:56\u001b[0m, in \u001b[0;36mcalc_loss_steering_vector\u001b[0;34m(generator, steering_vec, data, layer, iter, multiplier)\u001b[0m\n\u001b[1;32m     54\u001b[0m wrong_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28miter\u001b[39m):\n\u001b[0;32m---> 56\u001b[0m     value, activations \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_list_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mmax_gen_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gen_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     61\u001b[0m         value2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/VSC/llama3/llama/generation.py:325\u001b[0m, in \u001b[0;36mLlama.chat_completion\u001b[0;34m(self, dialogs, temperature, top_p, max_gen_len, logprobs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     max_gen_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmax_seq_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    322\u001b[0m prompt_tokens \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mencode_dialog_prompt(dialog) \u001b[38;5;28;01mfor\u001b[39;00m dialog \u001b[38;5;129;01min\u001b[39;00m dialogs\n\u001b[1;32m    324\u001b[0m ]\n\u001b[0;32m--> 325\u001b[0m generation_tokens, generation_logprobs, activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_gen_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gen_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logprobs:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    334\u001b[0m         {\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t, logprobs_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(generation_tokens, generation_logprobs)\n\u001b[1;32m    343\u001b[0m     ], activations\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSC/llama3/llama/generation.py:181\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, prompt_tokens, max_gen_len, temperature, top_p, logprobs, echo)\u001b[0m\n\u001b[1;32m    179\u001b[0m stop_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mstop_tokens))\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_prompt_len, total_len):\n\u001b[0;32m--> 181\u001b[0m     logits, activation_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_pos\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcur_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m temperature \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    183\u001b[0m         probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m temperature, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSC/llama3/llama/model.py:309\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, tokens, start_pos)\u001b[0m\n\u001b[1;32m    307\u001b[0m activation_tensor \u001b[38;5;241m=\u001b[39m activation_tensor\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    308\u001b[0m activation_vector \u001b[38;5;241m=\u001b[39m activation_tensor\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madding_activation_vector, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda()):\n\u001b[1;32m    310\u001b[0m     steering_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madding_activation_vector\u001b[38;5;241m.\u001b[39mrepeat(h\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    311\u001b[0m     steering_vector \u001b[38;5;241m=\u001b[39m steering_vector\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_loss = calc_loss_steering_vector(generator, torch.tensor(4096*[0]), (input_list_test, output_list_test), layer=10, iter=len(input_list_test), multiplier=0)\n",
    "losses_wo_instruct_vectors = {}\n",
    "print(f\"initial loss is {initial_loss}\")\n",
    "for k in range(12,29):\n",
    "    steering_vec = torch.load(f\"./steering_without_instruct/n_vector{k}.pt\")\n",
    "    for multiplier in range(1,40,2):\n",
    "        loss = calc_loss_steering_vector(generator, steering_vec, (input_list_test, output_list_test), layer=k, iter=len(input_list_test), multiplier=multiplier)\n",
    "        print(f\"Layer {k} loss with multiplier {multiplier} is {loss}\")\n",
    "        losses_wo_instruct_vectors[f\"{k},{multiplier}\"] = loss\n",
    "        if loss>0.8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 questions were wrongly classified\n",
      "initial loss is 0.6858864027538761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91523/1904716169.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  steering_vec = torch.load(f\"./c_and_n_vectors/vector{k}.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 questions were wrongly classified\n",
      "Layer 9 loss with multiplier 1 is 0.6652323580034448\n",
      "0 questions were wrongly classified\n",
      "Layer 9 loss with multiplier 3 is 0.7452667814113662\n",
      "137 questions were wrongly classified\n",
      "Layer 9 loss with multiplier 5 is 0.8511187607573266\n",
      "0 questions were wrongly classified\n",
      "Layer 10 loss with multiplier 1 is 0.8209982788296143\n",
      "0 questions were wrongly classified\n",
      "Layer 11 loss with multiplier 1 is 0.7848537005163595\n",
      "0 questions were wrongly classified\n",
      "Layer 11 loss with multiplier 3 is 0.8450946643717842\n",
      "0 questions were wrongly classified\n",
      "Layer 12 loss with multiplier 1 is 0.6772805507745298\n",
      "178 questions were wrongly classified\n",
      "Layer 12 loss with multiplier 3 is 0.6015490533562816\n",
      "986 questions were wrongly classified\n",
      "Layer 12 loss with multiplier 5 is 0.8752151462994965\n",
      "0 questions were wrongly classified\n",
      "Layer 13 loss with multiplier 1 is 0.6316695352839939\n",
      "107 questions were wrongly classified\n",
      "Layer 13 loss with multiplier 3 is 0.5593803786574844\n",
      "921 questions were wrongly classified\n",
      "Layer 13 loss with multiplier 5 is 0.8588640275387384\n",
      "0 questions were wrongly classified\n",
      "Layer 14 loss with multiplier 1 is 0.650602409638556\n",
      "144 questions were wrongly classified\n",
      "Layer 14 loss with multiplier 3 is 0.5869191049913928\n",
      "1043 questions were wrongly classified\n",
      "Layer 14 loss with multiplier 5 is 0.9552495697074178\n",
      "0 questions were wrongly classified\n",
      "Layer 15 loss with multiplier 1 is 0.5938037865748699\n",
      "0 questions were wrongly classified\n",
      "Layer 15 loss with multiplier 3 is 0.5094664371772754\n",
      "95 questions were wrongly classified\n",
      "Layer 15 loss with multiplier 5 is 0.650602409638556\n",
      "903 questions were wrongly classified\n",
      "Layer 15 loss with multiplier 7 is 0.9130808950086206\n",
      "0 questions were wrongly classified\n",
      "Layer 16 loss with multiplier 1 is 0.6944922547332225\n",
      "0 questions were wrongly classified\n",
      "Layer 16 loss with multiplier 3 is 0.6222030981067129\n",
      "0 questions were wrongly classified\n",
      "Layer 16 loss with multiplier 5 is 0.6781411359724644\n",
      "9 questions were wrongly classified\n",
      "Layer 16 loss with multiplier 7 is 0.7444061962134315\n",
      "756 questions were wrongly classified\n",
      "Layer 16 loss with multiplier 9 is 0.8554216867469998\n",
      "0 questions were wrongly classified\n",
      "Layer 17 loss with multiplier 1 is 0.7117039586919153\n",
      "0 questions were wrongly classified\n",
      "Layer 17 loss with multiplier 3 is 0.7667814113597321\n",
      "0 questions were wrongly classified\n",
      "Layer 17 loss with multiplier 5 is 0.8029259896729869\n",
      "0 questions were wrongly classified\n",
      "Layer 18 loss with multiplier 1 is 0.7151462994836538\n",
      "0 questions were wrongly classified\n",
      "Layer 18 loss with multiplier 3 is 0.7366609294320198\n",
      "0 questions were wrongly classified\n",
      "Layer 18 loss with multiplier 5 is 0.7728055077452746\n",
      "0 questions were wrongly classified\n",
      "Layer 18 loss with multiplier 7 is 0.7607573149741896\n",
      "366 questions were wrongly classified\n",
      "Layer 18 loss with multiplier 9 is 0.7521514629948433\n",
      "1029 questions were wrongly classified\n",
      "Layer 18 loss with multiplier 11 is 0.9423407917383982\n",
      "0 questions were wrongly classified\n",
      "Layer 19 loss with multiplier 1 is 0.6643717728055102\n",
      "0 questions were wrongly classified\n",
      "Layer 19 loss with multiplier 3 is 0.6635111876075755\n",
      "0 questions were wrongly classified\n",
      "Layer 19 loss with multiplier 5 is 0.6858864027538761\n",
      "46 questions were wrongly classified\n",
      "Layer 19 loss with multiplier 7 is 0.6222030981067129\n",
      "556 questions were wrongly classified\n",
      "Layer 19 loss with multiplier 9 is 0.7117039586919153\n",
      "1071 questions were wrongly classified\n",
      "Layer 19 loss with multiplier 11 is 0.938037865748725\n",
      "0 questions were wrongly classified\n",
      "Layer 20 loss with multiplier 1 is 0.6488812392426867\n",
      "0 questions were wrongly classified\n",
      "Layer 20 loss with multiplier 3 is 0.619621342512909\n",
      "0 questions were wrongly classified\n",
      "Layer 20 loss with multiplier 5 is 0.5989672977624777\n",
      "23 questions were wrongly classified\n",
      "Layer 20 loss with multiplier 7 is 0.5301204819277067\n",
      "329 questions were wrongly classified\n",
      "Layer 20 loss with multiplier 9 is 0.5447504302925955\n",
      "851 questions were wrongly classified\n",
      "Layer 20 loss with multiplier 11 is 0.809810671256464\n",
      "0 questions were wrongly classified\n",
      "Layer 21 loss with multiplier 1 is 0.6531841652323599\n",
      "0 questions were wrongly classified\n",
      "Layer 21 loss with multiplier 3 is 0.6041308089500855\n",
      "0 questions were wrongly classified\n",
      "Layer 21 loss with multiplier 5 is 0.5240963855421642\n",
      "77 questions were wrongly classified\n",
      "Layer 21 loss with multiplier 7 is 0.4647160068846765\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m steering_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./c_and_n_vectors/vector\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m multiplier \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_loss_steering_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteering_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_list_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_list_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiplier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss with multiplier \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmultiplier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     losses_centralized_vectors[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmultiplier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/VSC/llama3/eval/eval.py:56\u001b[0m, in \u001b[0;36mcalc_loss_steering_vector\u001b[0;34m(generator, steering_vec, data, layer, iter, multiplier)\u001b[0m\n\u001b[1;32m     54\u001b[0m wrong_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28miter\u001b[39m):\n\u001b[0;32m---> 56\u001b[0m     value, activations \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_list_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mmax_gen_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gen_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     61\u001b[0m         value2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/VSC/llama3/llama/generation.py:325\u001b[0m, in \u001b[0;36mLlama.chat_completion\u001b[0;34m(self, dialogs, temperature, top_p, max_gen_len, logprobs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     max_gen_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmax_seq_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    322\u001b[0m prompt_tokens \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mencode_dialog_prompt(dialog) \u001b[38;5;28;01mfor\u001b[39;00m dialog \u001b[38;5;129;01min\u001b[39;00m dialogs\n\u001b[1;32m    324\u001b[0m ]\n\u001b[0;32m--> 325\u001b[0m generation_tokens, generation_logprobs, activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_gen_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gen_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logprobs:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    334\u001b[0m         {\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t, logprobs_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(generation_tokens, generation_logprobs)\n\u001b[1;32m    343\u001b[0m     ], activations\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSC/llama3/llama/generation.py:181\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, prompt_tokens, max_gen_len, temperature, top_p, logprobs, echo)\u001b[0m\n\u001b[1;32m    179\u001b[0m stop_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mstop_tokens))\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_prompt_len, total_len):\n\u001b[0;32m--> 181\u001b[0m     logits, activation_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_pos\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcur_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m temperature \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    183\u001b[0m         probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m temperature, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSC/llama3/llama/model.py:304\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, tokens, start_pos)\u001b[0m\n\u001b[1;32m    299\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack(\n\u001b[1;32m    300\u001b[0m         [torch\u001b[38;5;241m.\u001b[39mzeros((seqlen, start_pos), device\u001b[38;5;241m=\u001b[39mtokens\u001b[38;5;241m.\u001b[39mdevice), mask]\n\u001b[1;32m    301\u001b[0m     )\u001b[38;5;241m.\u001b[39mtype_as(h)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m--> 304\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_layer_n \u001b[38;5;241m==\u001b[39m k:\n\u001b[1;32m    306\u001b[0m         activation_tensor \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/VSC/llama3/llama/model.py:246\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, start_pos, freqs_cis, mask)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    241\u001b[0m     x: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m     mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    245\u001b[0m ):\n\u001b[0;32m--> 246\u001b[0m     h \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, start_pos, freqs_cis, mask)\n\u001b[1;32m    247\u001b[0m     out \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_norm(h))\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSC/Coding_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/VSC/llama3/llama/model.py:45\u001b[0m, in \u001b[0;36mRMSNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 45\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype_as(x)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\n",
      "File \u001b[0;32m~/VSC/llama3/llama/model.py:42\u001b[0m, in \u001b[0;36mRMSNorm._norm\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_loss = calc_loss_steering_vector(generator, torch.tensor(4096*[0]), (input_list_test, output_list_test), layer=10, iter=len(input_list_test), multiplier=0)\n",
    "losses_centralized_vectors = {}\n",
    "print(f\"initial loss is {initial_loss}\")\n",
    "for k in range(9,29):\n",
    "    steering_vec = torch.load(f\"./c_and_n_vectors/vector{k}.pt\")\n",
    "    for multiplier in range(1,40,2):\n",
    "        loss = calc_loss_steering_vector(generator, steering_vec, (input_list_test, output_list_test), layer=k, iter=len(input_list_test), multiplier=multiplier)\n",
    "        print(f\"Layer {k} loss with multiplier {multiplier} is {loss}\")\n",
    "        losses_centralized_vectors[f\"{k},{multiplier}\"] = loss\n",
    "        if loss>0.8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46456/1326727220.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  good_vec_20 = torch.load(\"./c_and_n_vectors/vector20.pt\")\n",
      "/tmp/ipykernel_46456/1326727220.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  good_vec_21 = torch.load(\"./c_and_n_vectors/vector21.pt\")\n"
     ]
    }
   ],
   "source": [
    "#Analysing the vectors that work the best\n",
    "#layer 20 multilplier 10/11 has loss 0.24 with vector c_and_n\n",
    "#layer 21 multiplier 9 has loss 0.3 with vector c_and_n\n",
    "good_vec_20 = torch.load(\"./c_and_n_vectors/vector20.pt\")\n",
    "good_vec_21 = torch.load(\"./c_and_n_vectors/vector21.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.change_activation_layer(20)\n",
    "generator.change_activation_vector(10*good_vec_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, activ = generator.chat_completion([[\n",
    "             {\"role\":\"system\", \"content\":\"Answer with T if you believe the following statement is correct, answer with F if you believe it is false, please also give a short reasoning.\"},\n",
    "             {\"role\":\"system\", \"content\":\"You are a helpful assistant in casual reasoning, is the following reasoning true?\"},\n",
    "             {\"role\":\"user\", \"content\":\"Premise: Suppose there is a closed system of 3 variables, A, B and C. All the statistical relations among these 3 variables are as follows: A correlates with C. B correlates with C. However, A is independent of B. Hypothesis: There exists at least one confounder (i.e., common cause) of B and C.\"}]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generation': {'role': 'assistant',\n",
       "   'content': 'F. \\n\\nThere is no collider (common effect) of A and B, because B is independent of A.'}}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coding_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
