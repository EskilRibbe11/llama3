{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import fire\n",
    "\n",
    "from llama import Dialog, Llama\n",
    "import torch.distributed as dist\n",
    "import torch\n",
    "import os\n",
    "from data_casual import output_list_test, input_list_test\n",
    "from llama.model import ModelArgs, Transformer\n",
    "from llama.tokenizer import ChatFormat, Dialog, Message, Tokenizer\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, TypedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fairscale.nn.model_parallel.initialize import (\n",
    "    get_model_parallel_rank,\n",
    "    initialize_model_parallel,\n",
    "    model_parallel_is_initialized,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vec = torch.load(\"./steering_vector.pt\")\n",
    "steering_vec_2 = torch.load(\"./steering_vector_1.pt\")\n",
    "steering_vec_3 = torch.load(\"./steering_vector_2.pt\")\n",
    "steering_vec_layer_28 = torch.load(\"./steering_vector_layer28.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vec_layer_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Llama.build(\"./\", \"./tokenizer.model\",max_seq_len= 1024,max_batch_size= 4, activation=True, activation_layer=28,steering_vector=steering_vec_layer_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"./\"\n",
    "tokenizer_path = \"./tokenizer.model\"\n",
    "temperature = 0.6\n",
    "top_p = 0.9\n",
    "max_seq_len = 1024\n",
    "max_batch_size = 4\n",
    "max_gen_len= generator.model.params.max_seq_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.model.adding_activation_vector = 1.2*steering_vec_layer_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.model.adding_activation_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, activations = generator.chat_completion([input_list_test[1142]],\n",
    "                                   max_gen_len=max_gen_len,\n",
    "                                   top_p=top_p,\n",
    "                                   temperature=temperature)\n",
    "print(value, activations)\n",
    "\n",
    "n = len(input_list_test)\n",
    "loss = 0\n",
    "for i in range(n):\n",
    "    value, activations = generator.chat_completion([input_list_test[i]],\n",
    "                                      max_gen_len=max_gen_len,\n",
    "                                       top_p=top_p,\n",
    "                                       temperature=temperature)\n",
    "    value2 = 1 if value[0][\"generation\"][\"content\"]==\"T\" else 0\n",
    "    loss += 1/n*abs(int(output_list_test[i])-int(value2))\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coding_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
